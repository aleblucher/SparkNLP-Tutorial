{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nlp](https://dv-website.s3.amazonaws.com/uploads/2018/11/what_is_NLP.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Spark NLP\n",
    "### Megadados 2019 - Alessandra Blücher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por que eu não posso programar em português?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem milhares de linguagens diferentes de programação. Baixo ou alto nível, orientadas a objeto ou procedurais, mais ou menos intuitivas. Com uma variedade tão grande é possível encontrar uma para se adequar às mais diversas demandas. Entretanto, nenhuma dessas linguagens mencionadas pode ser considerada `natural`, como os dialetos que conhecemos.\n",
    "\n",
    "`Quais são as diferenças entre linguagens de programação e linguagens naturais que tornam impossível a ideia de programar com elas?`\n",
    "\n",
    "A resposta simples é que as linguagens naturais são inerentemente ambíguas. Um dos passos que o computador executa para entender determinada instrução é o parceamento da linguagem. Nós humanos também temos o mesmo processo de parceamento para compreender o português ou qualquer outra linguagem natural. Passivamente nós lidamos com problemas da linguagem natural que o computador não é capaz de lidar com tanta facilidade. Observe os exemplos a seguir de situações onde a linguagem natural possui algum aspecto que é um empecilho para o processamento:\n",
    "\n",
    "1. Ambiguidade\n",
    "\n",
    "    \"Ana encontrou o gerente da loja com o seu irmão.\" A frase é ambígua pois não se sabe se o irmão é de Ana ou do gerente. Esse tipo de situação é inexistente em linguagens de programação. Diferentes Processamentos de Linguagem Natural podem lidar com esse problema de algumas maneiras, uma delas é um parser probabilístico, que avalia qual das hipóteses é mais provável de ser o que o autor realmente quis dizer.\n",
    "    \n",
    "    \n",
    "2. Correferência\n",
    "\n",
    "    \"O ministro da educação atual pediu por uma pesquisa do índice de analfabetos acima de 60 anos no Brasil. Ele estima que o número deve ter diminuído em 27%.\" O comportamento presente nessa frase que é inexistente em linguagens de programação é a correferência apresentada pelo pronome 'ele' que se refere ao 'ministro da educação'.\n",
    "\n",
    "\n",
    "3. Polissemia\n",
    "    \n",
    "    \"Cabo\":\n",
    "    1. Posto militar; B. Acidente geográfico; C. Cabo da vassoura\n",
    "\n",
    "   \"Banco\":\n",
    "    1. Instituição comercial financeira; B. Assento\n",
    "\n",
    "   \"Manga\":\n",
    "    1. Parte da roupa; B. Fruta\n",
    "    \n",
    "    Esses são alguns exemplos de palavras polissêmicas, ou seja, palavras com múltiplos significados dependendo do contexto. Onde seria simples para nós distinguirmos qual sentido o contexto requer, fica evidente que para o computador poder fazer o mesmo é preciso um processamento específico da linguagem natural.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Curiosidade:\n",
    "`Lojban` é uma linguagem natural construída que não possui nenhuma ambiguidade. Teoricamente ela pode ser um dialeto comum e uma linguagem de programação ao mesmo tempo (alguns teste já foram feitos usando Lojban!).\n",
    "Para mais informações acesse: https://en.wikipedia.org/wiki/Lojban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você entendeu o `porquê` do processamento de linguagem natural, vamos entender mais sobre o `como`.\n",
    "\n",
    "###### Atenção! \n",
    "\n",
    "\n",
    "A partir desse momento vamos começar a efetivamente falar sobre e usar a ferramenta Spark NPL. As pipelines disponíveis pelo John Snow Labs possuem três idiomas: Inglês, Francês e Italiano.\n",
    "Nós utilizaremos `Inglês`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a instalação do Spark NPL siga as instruções oficiais oferecidas no site:\n",
    "\n",
    "https://nlp.johnsnowlabs.com/docs/en/install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduzindo Spark NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark NLP é uma biblioteca de processamento de linguagem natural open source, construída em cima do Apache Spark e Spark ML. A biblioteca produzida pelo John Snow Labs fornece annotations simples, eficazes e precisas para pipelines de Machine Learning, enquanto ela é facilmente escalável em ambientes distribuídos.\n",
    "\n",
    "A tabela abaixo mostra a comparação das funcionalidades do Spark NPL em comparação com outras bibliotecas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![functionalities](https://blog.dominodatalab.com/wp-content/uploads/2019/04/Pacific-AI-Table-1-cx-Sep-2019.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro aspecto excepecional do Spark NLP é a escalabilidade. A construção nativa no Apache Spark ML permite que o Spark NLP seja dimensionado em qualquer cluster Spark, no local ou em qualquer provedor de nuvem. As acelerações (speed ups) são otimizadas graças ao planejamento e cache de execução distribuída do Spark, que foram testados em praticamente qualquer plataforma de armazenamento e computação atual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observando a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para compreender melhor o uso do Spark NLP vamos começar com uma demonstração simples do uso da Pipeline pré treinada `explain_document`.\n",
    "\n",
    "Uma pipeline é a lista de etapas do processamento do texto. No caso do explain_document temos as seguintes etapas:\n",
    "\n",
    " * DocumentAssembler\n",
    " * SentenceDetector\n",
    " * Tokenizer\n",
    " * Lemmatizer\n",
    " * Stemmer\n",
    " * Part of Speech\n",
    " * SpellChecker (Norvig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "#Spark ML and SQL\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando uma sessão Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "2.2.1\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esse será nosso documento de teste para vizualizar as etapas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDoc = [\n",
    "\"life-changing It is change, continuing change, inivitable change, \\\n",
    "that is the  dominant factor in society today. \\\n",
    "No sensinble decision can be made any longer without \\\n",
    "taking into account not only the world as it is, \\\n",
    "but the world as it will be. \"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Não se assuste com os erros gramaticais, nós iremos lidar com eles mais tarde!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declarando nossa pipeline pré treinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain_document_ml download started this may take some time.\n",
      "Approx size to download 9,4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Carrega a versão em inglês da pipeline explain_document_dl,\n",
    "# os modelos pré treinado e todas suas dependencias - cache local\n",
    "pipeline = PretrainedPipeline('explain_document_ml', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotate() o algoritmo de cada estágio da pipelina\n",
    "result = pipeline.annotate(testDoc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos observar os resultados para enteder melhor o resultado de cada etapa do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['life-changing It is change, continuing change, inivitable change, that is the  dominant factor in society today.',\n",
       "  'No sensinble decision can be made any longer without taking into account not only the world as it is, but the world as it will be.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['sentence'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora vamos de frases para tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['life-changing',\n",
       "  'It',\n",
       "  'is',\n",
       "  'change',\n",
       "  ',',\n",
       "  'continuing',\n",
       "  'change',\n",
       "  ',',\n",
       "  'inivitable',\n",
       "  'change',\n",
       "  ',',\n",
       "  'that',\n",
       "  'is',\n",
       "  'the',\n",
       "  'dominant',\n",
       "  'factor',\n",
       "  'in',\n",
       "  'society',\n",
       "  'today',\n",
       "  '.',\n",
       "  'No',\n",
       "  'sensinble',\n",
       "  'decision',\n",
       "  'can',\n",
       "  'be',\n",
       "  'made',\n",
       "  'any',\n",
       "  'longer',\n",
       "  'without',\n",
       "  'taking',\n",
       "  'into',\n",
       "  'account',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['token'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Checking & Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reparou em alguns erros de ortografia? Vamos ver se a pipeline corrigiu!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preste atenção em `inivitable` e `sensinble`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lifechanging',\n",
       "  'It',\n",
       "  'is',\n",
       "  'change',\n",
       "  ',',\n",
       "  'continuing',\n",
       "  'change',\n",
       "  ',',\n",
       "  'inevitable',\n",
       "  'change',\n",
       "  ',',\n",
       "  'that',\n",
       "  'is',\n",
       "  'the',\n",
       "  'dominant',\n",
       "  'factor',\n",
       "  'in',\n",
       "  'society',\n",
       "  'today',\n",
       "  '.',\n",
       "  'No',\n",
       "  'sensible',\n",
       "  'decision',\n",
       "  'can',\n",
       "  'be',\n",
       "  'made',\n",
       "  'any',\n",
       "  'longer',\n",
       "  'without',\n",
       "  'taking',\n",
       "  'into',\n",
       "  'account',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['checked'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline que usamos já realiza a correção da ortografia, mas é possível treinar ela de três formas diferentes:\n",
    "* Norvig Approach:\n",
    "    - retorna token e auto corrige baseado num dado dicionário\n",
    "* Symmetric Delete:\n",
    "    - usa métricas de distância para achar possíveis palavras\n",
    "* Context Aware:\n",
    "    - mais preciso, julga as palavras no contexto\n",
    "    - baseado em deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos ver os lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmas o resultado de um processo de lematização, que agrupo palavras que estejam relacionadas a outras e ajusta as flexões das palavras para interpretá-las melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lifechanging',\n",
       "  'It',\n",
       "  'be',\n",
       "  'change',\n",
       "  ',',\n",
       "  'continue',\n",
       "  'change',\n",
       "  ',',\n",
       "  'inevitable',\n",
       "  'change',\n",
       "  ',',\n",
       "  'that',\n",
       "  'be',\n",
       "  'the',\n",
       "  'dominant',\n",
       "  'factor',\n",
       "  'in',\n",
       "  'society',\n",
       "  'today',\n",
       "  '.',\n",
       "  'No',\n",
       "  'sensible',\n",
       "  'decision',\n",
       "  'can',\n",
       "  'be',\n",
       "  'make',\n",
       "  'any',\n",
       "  'long',\n",
       "  'without',\n",
       "  'take',\n",
       "  'into',\n",
       "  'account',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'be',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['lemma'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E os stems? São diferentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O stemmer é um algoritmo para remover terminações flexionais e derivacionais, a fim de reduzir as formas de palavras a um radical comum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lifechang',\n",
       "  'it',\n",
       "  'i',\n",
       "  'chang',\n",
       "  ',',\n",
       "  'continu',\n",
       "  'chang',\n",
       "  ',',\n",
       "  'inevit',\n",
       "  'chang',\n",
       "  ',',\n",
       "  'that',\n",
       "  'i',\n",
       "  'the',\n",
       "  'domin',\n",
       "  'factor',\n",
       "  'in',\n",
       "  'societi',\n",
       "  'todai',\n",
       "  '.',\n",
       "  'no',\n",
       "  'sensibl',\n",
       "  'decis',\n",
       "  'can',\n",
       "  'be',\n",
       "  'made',\n",
       "  'ani',\n",
       "  'longer',\n",
       "  'without',\n",
       "  'take',\n",
       "  'into',\n",
       "  'account',\n",
       "  'not',\n",
       "  'onli',\n",
       "  'the',\n",
       "  'world',\n",
       "  'a',\n",
       "  'it',\n",
       "  'i',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'world',\n",
       "  'a',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['stem'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pos](https://miro.medium.com/max/1170/1*CbZE2ZTBlmswW84Knjbqkg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `CC` coordinating conjunction\n",
    "* `CD` cardinal digit\n",
    "* `DT` determiner\n",
    "* `EX` existential there (like: “there is” … think of it like “there exists”)\n",
    "* `FW` foreign word\n",
    "* `IN` preposition/subordinating conjunction\n",
    "* `JJ` adjective ‘big’\n",
    "* `JJR` adjective, comparative ‘bigger’\n",
    "* `JJS` adjective, superlative ‘biggest’\n",
    "* `LS` list marker 1)\n",
    "* `MD` modal could, will\n",
    "* `NN` noun, singular ‘desk’\n",
    "* `NNS` noun plural ‘desks’\n",
    "* `NNP` proper noun, singular ‘Harrison’\n",
    "* `NNPS` proper noun, plural ‘Americans’\n",
    "* `PDT` predeterminer ‘all the kids’\n",
    "* `POS` possessive ending parent’s\n",
    "* `PRP` personal pronoun I, he, she\n",
    "* `PRP` possessive pronoun my, his, hers\n",
    "* `RB` adverb very, silently,\n",
    "* `RBR` adverb, comparative better\n",
    "* `RBS` adverb, superlative best\n",
    "* `RP` particle give up\n",
    "* `TO`, to go ‘to’ the store.\n",
    "* `UH` interjection, errrrrrrrm\n",
    "* `VB` verb, base form take\n",
    "* `VBD` verb, past tense took\n",
    "* `VBG` verb, gerund/present participle taking\n",
    "* `VBN` verb, past participle taken\n",
    "* `VBP` verb, sing. present, non-3d take\n",
    "* `VBZ` verb, 3rd person sing. present takes\n",
    "* `WDT` wh-determiner which\n",
    "* `WP` wh-pronoun who, what\n",
    "* `WP` possessive wh-pronoun whose\n",
    "* `WRB` wh-abverb where, when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você já entendeu o processamento que o Spark NLP realiza, vamos brincar com algumas ferramentas. Uma delas é o POS, ou Part of Speech, que classifica a categoria de cada token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life-changing', 'VBG'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('change', 'NN'),\n",
       " (',', ','),\n",
       " ('continuing', 'VBG'),\n",
       " ('change', 'NN'),\n",
       " (',', ','),\n",
       " ('inivitable', 'JJ'),\n",
       " ('change', 'NN'),\n",
       " (',', ','),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('dominant', 'JJ'),\n",
       " ('factor', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('society', 'NN'),\n",
       " ('today', 'NN'),\n",
       " ('.', '.'),\n",
       " ('No', 'DT'),\n",
       " ('sensinble', 'JJ'),\n",
       " ('decision', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('made', 'VBN'),\n",
       " ('any', 'DT'),\n",
       " ('longer', 'RBR'),\n",
       " ('without', 'IN'),\n",
       " ('taking', 'VBG'),\n",
       " ('into', 'IN'),\n",
       " ('account', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('only', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [content['pos'] for content in result]\n",
    "token = [content['token'] for content in result]\n",
    "# vamos juntar token e tag para observá-los lado a lado\n",
    "list(zip(token[0], pos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ent](https://miro.medium.com/max/1200/1*DED1LGhEok0s2mUUIFbv0A.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função do `Entity Recognizer` é localizar e classificar as menções de entidades nomeadas em textos não estruturado em categorias predefinidas, como nomes de pessoas, organizações, locais, expressões de tempo, quantidades, entre outros - dependendo da pipeline utilizada. Vamos ver como funciona!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognize_entities_dl download started this may take some time.\n",
      "Approx size to download 157,9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\n",
    "result = pipeline.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entities', 'document', 'token', 'ner', 'embeddings', 'sentence']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Mona Lisa is a 16th century oil painting created by Leonardo.',\n",
       " \"It's held at the Louvre in Paris.\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Mona',\n",
       " 'Lisa',\n",
       " 'is',\n",
       " 'a',\n",
       " '16th',\n",
       " 'century',\n",
       " 'oil',\n",
       " 'painting',\n",
       " 'created',\n",
       " 'by',\n",
       " 'Leonardo',\n",
       " '.',\n",
       " \"It's\",\n",
       " 'held',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Louvre',\n",
       " 'in',\n",
       " 'Paris',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('Mona', 'I-PER'),\n",
       " ('Lisa', 'I-PER'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('16th', 'O'),\n",
       " ('century', 'O'),\n",
       " ('oil', 'O'),\n",
       " ('painting', 'O'),\n",
       " ('created', 'O'),\n",
       " ('by', 'O'),\n",
       " ('Leonardo', 'I-PER'),\n",
       " ('.', 'O'),\n",
       " (\"It's\", 'I-ORG'),\n",
       " ('held', 'O'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Louvre', 'I-LOC'),\n",
       " ('in', 'O'),\n",
       " ('Paris', 'I-LOC'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(result['token'], result['ner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mona Lisa', 'Leonardo', \"It's\", 'Louvre', 'Paris']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sen](https://cdn-images-1.medium.com/max/800/1*NF6AdPk6sOMNNbQE5glvEQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark NLP vem com dois tipos de Sentiment analysis:\n",
    "\n",
    "*  Sentiment Detector: define um grupo de tokens como positivos, negativos, incremento ou decremento\n",
    "*  Vivekn Sentiment Approach: treina um modelo ML com um sete de exemplos positivos e negativos\n",
    "\n",
    "Ambos os tipos são treináveis para mais emoções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_sentiment download started this may take some time.\n",
      "Approx size to download 4,9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('analyze_sentiment', 'en') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I hate the movie. Even if the landscapes were absolutely stunning, the writing was very poor and it made the movie so much worse. I wouldnt recomment it.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(result['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira de entender o potencial de qualquer ferramenta é ver as aplicações que a utilizam. Um exemplo interessante do uso do Spark NLP é o projeto apresentado por Maziyar Pahani, que usou desse recurso para processar o \"Relatório da Investigação de Interferência Russa na Eleição Presidencial Estadunidense de 2016\", mais comumente conhecido como `relatório Muller`.\n",
    "\n",
    "O autor do projeto o divide em três etapas:\n",
    "* Primeira etapa: usar as pipelines e modelos pré treinados do Spark NLP para fazer o processamento do Relatório\n",
    "* Segunda etapa: usar os modelos treinados por BERT, treinando um modelo POS tagger com Spark NLP, limpeza de dados e extração de palavras chaves e frases por POS e NER chunking\n",
    "* Terceira etapa: a partir de algoritmos de grafos do GraphFrames, fazer clustering por topic modelings do Spark ML. A visualização da rede é oferecida por Gephi.\n",
    "\n",
    "Nesse link o autor possui uma explicação extensa sobre o seu processo, abordando diversos dos mesmos tópicos tratados neste tutorial:\n",
    "\n",
    "[https://hackernoon.com/mueller-report-for-nerds-spark-meets-nlp-with-tensorflow-and-bert-part-1-32490a8f8f12]\n",
    "\n",
    "As imagens incluídas são alguns os resultados interessantes obtidos por Maziyar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![app](https://hackernoon.com/photos/JTw2M3rQabaxNg3EFoNIxjmC1ZB3-r9230p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![trump](https://hackernoon.com/photos/JTw2M3rQabaxNg3EFoNIxjmC1ZB3-ug383x47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![insper](https://3.bp.blogspot.com/-fvRAgvDodjY/T8SgztDikmI/AAAAAAAAAww/SaYB30Oog6I/s1600/insper.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crédito das Imagens \n",
    "\n",
    "* https://dv-website.s3.amazonaws.com/uploads/2018/11/what_is_NLP.jpg\n",
    "* https://blog.dominodatalab.com/wp-content/uploads/2019/04/Pacific-AI-Table-1-cx-Sep-2019.png\n",
    "* https://miro.medium.com/max/1170/1*CbZE2ZTBlmswW84Knjbqkg.png\n",
    "* https://miro.medium.com/max/1200/1*DED1LGhEok0s2mUUIFbv0A.jpeg\n",
    "* https://cdn-images-1.medium.com/max/800/1*NF6AdPk6sOMNNbQE5glvEQ.png\n",
    "* https://hackernoon.com/photos/JTw2M3rQabaxNg3EFoNIxjmC1ZB3-r9230p2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
